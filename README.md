# BasementBrewAI ğŸŸ§ Industrial ML Terminal

```
================================================================================
                                                                                
  ####    B A S E M E N T   B R E W   A I                                     
  #  #    +-----------------------------+                                     
  ####    | Industrial ML Terminal v2.0 |                                     
  #  #    +-----------------------------+                                     
  ####    NOW WITH LLM CAPABILITIES                                          
                                                                                
================================================================================
```

> *"Where neural networks meet the underground - now brewing language models"* 

[![Python](https://img.shields.io/badge/Python-3.8+-orange.svg?style=flat-square)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-green.svg?style=flat-square)](https://pytorch.org)
[![Dear PyGui](https://img.shields.io/badge/Dear%20PyGui-1.0+-yellow.svg?style=flat-square)](https://github.com/hoffstadt/DearPyGui)
[![License](https://img.shields.io/badge/License-MIT-red.svg?style=flat-square)](LICENSE)

## ğŸŸ§ System Overview

Welcome to the basement, operator. **BasementBrewAI** is a retro-themed ML/AI training terminal that combines 80's industrial computing aesthetics with modern deep learning capabilities. Now featuring **LLM fine-tuning** with GPT-OSS support!

### âš¡ Core Features

#### Traditional ML
- **Industrial Terminal Interface** - Orange & green phosphor display aesthetics
- **Real-time Training Visualization** - Watch losses drop in glorious ASCII
- **Multi-Model Support** - MLP, CNN, LeNet-5, ResNet-18/34
- **Dataset Plugin System** - MNIST, CIFAR-10, FashionMNIST + custom loaders
- **GPU Acceleration** - CUDA support with real-time VRAM monitoring
- **Model Export** - ONNX & TorchScript for production

#### LLM Capabilities (NEW!)
- **GPT-OSS-20B Support** - OpenAI's open-source model integration
- **QLoRA Fine-tuning** - 4-bit quantization for 12GB GPUs
- **Data Pipeline** - Web scraping, cleaning, tokenization
- **Safety Controls** - Danger mode with explicit warnings
- **Inference Engine** - Chat interface for testing models
- **Multi-source Scraping** - ArXiv, Reddit, web content

## ğŸŸ§ Quick Start

### Prerequisites

```bash
[SYSTEM] Checking requirements...
> Python 3.8-3.11 [REQUIRED]
> NVIDIA GPU with CUDA [RECOMMENDED]
> 8GB+ RAM [MINIMUM]
> 50GB+ Storage [FOR LLMs]
```

### Installation

```bash
# Clone the basement
git clone https://github.com/yourusername/BasementBrewAI.git
cd BasementBrewAI

# Create virtual environment
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# For GPU support (CUDA 12.4)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

### Launch Terminal

```bash
# Windows - Full retro experience
run_basement.bat

# Cross-platform
python run.py

# Direct launch
python trainer/app.py
```

## ğŸŸ§ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MAIN PROCESS (GUI)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Dear PyGui â”‚  â”‚ Retro Theme  â”‚  â”‚  LLM UI Tab   â”‚  â”‚
â”‚  â”‚   Display   â”‚  â”‚  Controller  â”‚  â”‚   Interface   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                      â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                        â”‚                                 â”‚
â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                            â”‚
â”‚                   â”‚ Queue   â”‚                            â”‚
â”‚                   â”‚ Manager â”‚                            â”‚
â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 WORKER PROCESS (Training)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   PyTorch   â”‚  â”‚  LLM/QLoRA   â”‚  â”‚  Data Pipelineâ”‚  â”‚
â”‚  â”‚   Engine    â”‚  â”‚   Training   â”‚  â”‚   Processing  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸŸ§ Feature Modules

### Traditional ML Training
- **Models**: MLP, CNN, LeNet-5, ResNet-18/34
- **Datasets**: MNIST, CIFAR-10, FashionMNIST, custom plugins
- **Training**: Real-time monitoring, auto-save, experiment tracking
- **Testing**: Batch inference, single image prediction
- **Export**: ONNX, TorchScript formats

### LLM Fine-tuning (NEW!)
- **Models**: GPT-OSS-20B (fits 12GB VRAM with QLoRA)
- **Data Sources**: 
  - ArXiv papers
  - Reddit posts
  - Web content
- **Processing Pipeline**:
  - Tokenization (GPT-2, tiktoken)
  - Cleaning (PII removal, deduplication)
  - Formatting (Alpaca, Vicuna, ChatML)
- **Safety**: Danger mode toggle with comprehensive warnings

## ğŸŸ§ Usage Guide

### Training Traditional Models

1. **Select Dataset** - Choose from available data modules
2. **Pick Architecture** - MLP for basics, ResNet for power
3. **Configure Hyperparameters** - Epochs, batch size, learning rate
4. **Enable GPU** - Check VRAM meter
5. **START TRAINING** - Monitor in real-time

### Fine-tuning LLMs

1. **Navigate to LLM Lab** tab
2. **Configure Data Sources** - Select scrapers and queries
3. **Set QLoRA Parameters** - Rank, alpha, quantization
4. **Review Safety Settings** - Keep guardrails enabled
5. **Start Fine-tuning** - Monitor perplexity and loss

## ğŸŸ§ Model Zoo

### Computer Vision Models
| Model | Parameters | Best For |
|-------|------------|----------|
| **Simple MLP** | ~800K | Quick experiments, MNIST |
| **BasicCNN** | ~1.2M | Image classification basics |
| **LeNet-5** | ~60K | Classic CNN architecture |
| **ResNet-18** | ~11M | Serious image classification |
| **ResNet-34** | ~21M | When you need more depth |

### Language Models
| Model | Parameters | VRAM Required | Status |
|-------|------------|---------------|---------|
| **GPT-OSS-20B** | 21B (3.6B active) | 12-16GB | Ready |
| **GPT-OSS-120B** | 117B (5.1B active) | 60GB+ | Planned |

## ğŸŸ§ Data Pipeline

```python
from trainer.llm.data import DatasetManager, DatasetConfig

# Configure data collection
config = DatasetConfig(
    name="my_dataset",
    sources=["arxiv", "reddit", "web"],
    queries=["machine learning", "AI safety"],
    max_items_per_source=1000
)

# Run pipeline
manager = DatasetManager(config)
result = manager.create_dataset(dataset_type="instruction")
```

## ğŸŸ§ Command Reference

```bash
# Application
python run.py                          # Launch with header
python trainer/app.py                  # Direct launch

# Testing
python test_model_demo.py              # Test inference
python test_llm_pipeline.py            # Test LLM data pipeline

# Maintenance
python cleanup_failed_runs.py          # Interactive cleanup
python cleanup_auto.py                 # Auto cleanup
python force_clean_runs.py             # Force clean all
python kill_stuck_runs.py              # Kill stuck processes

# Database
python trainer/db.py                   # Test database operations

# Build
pyinstaller --onefile --windowed --icon=trainer\assets\icon.ico --name "BasementBrewAI" trainer\app.py
```

## ğŸŸ§ System Requirements

### Minimum
- **OS**: Windows 10/11, Linux, macOS
- **Python**: 3.8 - 3.11
- **RAM**: 8GB
- **Storage**: 10GB
- **GPU**: Optional (CPU training supported)

### Recommended (for LLMs)
- **RAM**: 32GB+
- **GPU**: NVIDIA RTX 3070 Ti or better (12GB+ VRAM)
- **Storage**: 100GB+ (for models and datasets)
- **CUDA**: 11.8 or 12.4

## ğŸŸ§ Project Structure

```
BasementBrewAI/
â”œâ”€â”€ trainer/
â”‚   â”œâ”€â”€ app.py                 # Main application
â”‚   â”œâ”€â”€ llm/                   # LLM module
â”‚   â”‚   â”œâ”€â”€ models/            # Model implementations
â”‚   â”‚   â”œâ”€â”€ training/          # Training pipelines
â”‚   â”‚   â”œâ”€â”€ data/              # Data processing
â”‚   â”‚   â”‚   â”œâ”€â”€ scrapers/      # Web scrapers
â”‚   â”‚   â”‚   â””â”€â”€ processors/    # Tokenizers, cleaners
â”‚   â”‚   â”œâ”€â”€ inference/         # Generation engine
â”‚   â”‚   â””â”€â”€ safety/            # Danger mode controls
â”‚   â”œâ”€â”€ models/                # Traditional ML models
â”‚   â”œâ”€â”€ data/                  # Dataset loaders
â”‚   â””â”€â”€ assets/                # Icons and resources
â”œâ”€â”€ saved_models/              # Trained model storage
â”œâ”€â”€ datasets/                  # Processed datasets
â”œâ”€â”€ experiments.db             # Training history
â””â”€â”€ requirements.txt           # Dependencies
```

## ğŸŸ§ Troubleshooting

### Common Issues

**Q: Stuck training runs won't terminate**  
A: Fixed! Auto-cleanup on startup + enhanced kill functions

**Q: GUI shows question marks**  
A: All Unicode replaced with ASCII blocks

**Q: LLM training OOM errors**  
A: Enable QLoRA, reduce batch size, use gradient accumulation

**Q: Data pipeline fails**  
A: Check internet connection, install all dependencies from requirements.txt

## ğŸŸ§ Recent Updates

### v2.0 - LLM Integration
- âœ… GPT-OSS-20B support with QLoRA
- âœ… Complete data pipeline (scraping â†’ cleaning â†’ formatting)
- âœ… Safety controls and danger mode
- âœ… Enhanced process management
- âœ… Startup auto-cleanup for stuck runs

### v1.0 - Initial Release
- âœ… Multi-process architecture
- âœ… Retro terminal interface
- âœ… Traditional ML models
- âœ… Real-time training visualization

## ğŸŸ§ Contributing

Pull requests welcome! Please maintain:
- ASCII art only (no Unicode except where necessary)
- Orange/green color scheme
- Industrial terminal theme
- Comprehensive error handling
- Safety-first approach for LLM features

## ğŸŸ§ License

MIT License - See [LICENSE](LICENSE) file

## ğŸŸ§ Acknowledgments

- Built with [Dear PyGui](https://github.com/hoffstadt/DearPyGui)
- Powered by [PyTorch](https://pytorch.org)
- LLM support via [Transformers](https://huggingface.co/transformers)
- Inspired by 80's industrial control systems
- ASCII art hand-crafted in the basement

---

```
[SYSTEM] BasementBrewAI v2.0 initialized
[STATUS] Ready for neural network operations
[MODE]   Industrial ML Terminal + LLM Laboratory
[SAFETY] Guardrails ENABLED
>>> _
```

*Remember: Real hackers train in the basement. Now with language models.* ğŸŸ§